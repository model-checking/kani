# Testing

Testing in RMC is carried out in multiple ways. There is at least
two very good reasons to do it:
 1. **Software regression**: A regression is a type of bug
    that appears after a change is introduced where a feature that
    was previously working has unexpectedly stopped working.

    Regression testing allows one to prevent a software regression
    from happening by running a comprehensive set of working tests
    before any change is committed to the project.
 2. **Software metrics**: A metric is a measure of software
    characteristics which are quantitative and countable. Metrics are
    particularly valuable for project management purposes.

We recommend reading our section on [Regression Testing](#regression-testing)
if you are interested in RMC development. At present, we obtain metrics based
on the [RMC dashboard](./dashboard.md).

# Regression testing

RMC counts with a quite extensive range of tests to perform regression testing.
Regression testing can be executed by running the command:

```
./scripts/rmc-regression.sh
```

The `rmc-regression.sh` script executes different testing commands, which we classify into:
 * [RMC testing suites](#rmc-testing-suites)
 * [Rust unit tests](#rust-unit-tests)
 * [Script-based tests](#script-based-tests)

See below for a description of each one.

Note that regression testing is run whenever a Pull Request is opened, updated or merged
into the main branch. Therefore, it is a good idea to run regression testing locally before
submitting a Pull Request for RMC.

## RMC testing suites

The RMC testing suites are the main testing resource for RMC. In most cases, the
tests contained in the RMC testing suites are single Rust files that are run
using the following command:

```
rmc file.rs <options>
```

Command-line options `<options>` can be passed to the test by adding a special
comment to the file.
Read more about it in the [Testingoptions](#testing-options) section.

In particular, the RMC testing suites are composed of:
 * `rmc`: The main testing suite for RMC. The test is a single Rust file that is
          run through RMC. In general, the test passes if verification with RMC
          is successful, otherwise it fails.
 * `firecracker`: Works like `rmc` but contains tests inspired by
   [Firecracker](https://github.com/firecracker-microvm/firecracker) code.
 * `prusti`: Works like `rmc` but contains tests from the
   [Prusti](https://github.com/viperproject/prusti-dev) tool.
 * `smack`: Works like `rmc` but contains tests from the
   [SMACK](https://github.com/smackers/smack) tool.
 * `expected`: Similar to `rmc` but with an additional check which ensures that
               lines appearing in `*.expected` files appear in the output
               generated by `rmc`.
 * `cargo-rmc`: This suite is designed to test the `cargo-rmc` command. As such,
                this suite works with packages instead of single Rust files.
                Flags can be specified in the `Cargo.toml` configuration file.
                Similar to the `expected` suite, we look for `*.expected` files
                for each function under test.

We have extended
[`compiletest`](https://rustc-dev-guide.rust-lang.org/tests/intro.html) (the
Rust compiler testing framework) to work with these suites. That way, we take
advantage of all `compiletest` features (e.g., parallel execution).

### Testing stages

The process of running single-file tests is split into three stages:
 * `check`: This stage uses the Rust front-end to detect if the example is valid
   Rust code.
 * `codegen`: This stage uses the RMC back-end to determine if we can generate
   GotoC code.
 * `verify`: This stage uses CBMC to obtain a verification result.

If a test fails, the error message will include the stage where it failed:

```
error: test failed: expected check success, got failure
```

When working on a test that is expected to fail, there are two options to
indicate an expected failure. The first one is to add a comment

```rust
// rmc-<stage>-fail
```
at the top of the test file, where `<stage>` is the stage where the test is
expected to fail. The other option is to use the predicate
`__VERIFIER_expect_fail(cond, message)` included in the RMC prelude. The testing
framework expects one `EXPECTED FAIL` message in the verification output for
each use of the predicate.

> **Warning:** Note that `__VERIFIER_expect_fail` is only useful to indicate
> failure in the `verify` stage, errors in other stages will be considered
> testing failures.

### Testing options

Many tests will require passing command-line options to RMC. These options can
be specified in single Rust files by adding a comment at the top of the file:
```
// rmc-flags: <options>
```

For example, to increase the unwinding value to 4 in a test, we can write:

```
// rmc-flags: --cbmc-args --unwind 4
```

For `cargo-rmc` tests, the preferred way to pass command-line options is adding
them to `Cargo.toml` below the `[rmc.flags]` marker.

## Rust unit tests

These tests follow the
[Rust unit testing](https://doc.rust-lang.org/rust-by-example/testing/unit_testing.html)
style.

At present, RMC only uses unit tests in the
[cbmc crate](https://github.com/model-checking/rmc/tree/main/compiler/cbmc)
to test the
[identity symbol table transformer](https://github.com/model-checking/rmc/blob/main/compiler/cbmc/src/goto_program/symtab_transformer/identity_transformer.rs).

## Script-based tests

These are tests which are run using scripts. Scripting gives us the ability to
perform ad-hoc checks that cannot be done otherwise. They are currently used
for:
 * Standard library codegen
 * Firecracker virtio codegen
 * Diamond dependency
 * Type mismatch

In fact, most of them are equivalent to running `cargo rmc` and performing
checks on the output. The downside to scripting is that these tests will always
be run, even if there have not been any changes since the last time the
regression was run.

> **Warning:** `cargo rmc` is under heavy development at the moment. Because of
> that, this section may become outdated soon.
